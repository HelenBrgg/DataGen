data: #handles files and their csv-subfiles that are in the 'data-directory'
  mode: seed_data #seed_data or dummy_data
  datapath: 'data'

   #looks for these csv files in the files from files directory
  csvs: #e.g. ["TS-PL-20_01.csv" "TS-PL-27_19.csv"]
   
   #look for the csv files in these files
  files: #e.g.['TS-PL-20','TS-PL-27']
   #if the mode is seeddata, one can set dummy data here
  dummy: [[1, 1, 1, 1, ], [2, 2, 2, 2,],[3, 3, 3, 3], [5, 5, 5, 5,], [8, 8, 8, 8,],[9, 9,9, 9,], [10, 10, 10, 10,], [12, 12, 12, 12,], [11, 11, 11, 11,],[8, 8, 8, 8,],[7, 7, 7, 7,], [6, 6, 6, 6,] ,[5, 5, 5, 5,], [4, 4, 4, 4,],[1, 1, 1, 1, ], [2, 2, 2, 2,],[3, 3, 3, 3],[2, 2, 2, 2,],[3, 3, 3, 3]]
extend: 
  path_output: "output_data/extened_series"
  series_list:

    - series: 
      name: serieTrainNegative3Anomalies
      standardizing: #list with one scale for each column, 
                    #normalizes and scales data between min and max val, shifts to desired mean, if provided one
        - scale: #scale e.g. for columns that are wrongly calibrated
          min_val: 0
          max_val: # e.g. 2   
          desired_mean: # default NOne
          column : 3 #
      baseediting:
        stretching: #stretches or shortens the data by given factor, 
        #if <1 it drops lines, else interpolates
          factor: #e.g. 0.01
          method: linear #for stretching, linear or pad
          limit_direction: False # for padding
        noising: #Generate Gaussian noise with mean 0 and variance proportional to the column and that is scaled by 'factor'
          factor: # equals sigma in Gaussian noise, a smaller number leads to lesser smoothing
        concatenating: # repeatedly concatenates the dataframes a given number of times, and smoothes the edges
          times:  # dataframe times+1 
          smooth_number:  # e.g. 1000, how many numbers left and right at the cut are being smoothed
          smooth_factor: # # equals sigma in Gaussian smoothing, a smaller number leads to less smoothing
        smoothing: #reduces the noise by applying gaussian smoothing
          factor:  # equals sigma in Gaussian smoothing, a smaller number leads to less smoothing
      projections: # applies pattern and anomalies on the timeseries
              #patterns:
              # random walk: pattern, that randomly chooses steps from -1,0,1
              # sine wave
              #anomalies:
              #square shaped anomaly 
              #bell shaped
        - projection: projection1
          column: #e.g. 3
          type:  #sine or random walk 
          frequency:  # only for sine
          amplitude:  #for random walk and sine, default for random walk is 1.5 and for sine is range of array.max()-array.min()*0.3

      anomalies:
        - anomaly: anomaly1
          column: #
          type:  # square or bell
          position: #e.g. 80000 #middle of anomaly
          half_width: #e.g. 100 # anomaly left and right of position
          height_factor: #e.g. 0.5 #additional to height at position
      generate:
        duration: 0 #len(Smat[1])
        substance_vals : [0, 0.09, 0.01, .8] # factors with which the features will go into the output 
        
        distribution_vals: [0, 0.1, 0.2, 0.7] #distribution width chagnes through these factors
        conesize: 400 #must be even
        output_path: output_data/new_feature
        final_subsampling: 1
        output_path_subsampled: output_data/new_feature_subsampled
    

   